# lmms-eval-for-llama
lmms-eval modified for evaluation for llama-3.2-11B-Vision-Instruct

| Benchmark | Value  | Stderr |
|----------|--------|--------|
| VQAv2    | 0.6808 | 0.0009 |
| TextVQA  | 0.7649 | 0.0056 |
| DocVQA   | 0.8959 | 0.0038 |
| MMMU     | 0.4033 | N/A    |
| ChartQA  | 0.6984 | 0.0092 |
| InfoVQA  | 0.6086 | 0.0089 |
| AI2D     | 0.7497 | 0.0078 |
| | | |
| AI2D(CoT) no sample log | 0.5955 | 0.0088 |
